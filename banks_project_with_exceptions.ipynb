{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Saylani Mass Training Program**\n",
    "### **Cloud Data Engineering Module by Qasim Hassan**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A basice Extract, Transform and Load (ETL) pipeline using web scrapping, pandas and sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import StringIO\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "# from icecream import ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 0: Maintaining a Log File\n",
    "This step is done to record the logs while performing ETL and it is not neccessary in an ETL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(message):\n",
    "    \"\"\"Logs the given message to a log file.\n",
    "\n",
    "    This function logs the mentioned message of a given stage of the\n",
    "    code execution to a log file. If the log directory or file doesn't exist,\n",
    "    it will attempt to create them. Function returns nothing.\n",
    "    \"\"\"\n",
    "\n",
    "    log_dir = './logs'\n",
    "    log_file = os.path.join(log_dir, 'code_log.txt')\n",
    "\n",
    "    try:\n",
    "        # Ensure the log directory exists\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        \n",
    "        # Open the log file in append mode and write the log\n",
    "        with open(log_file, 'a') as f:\n",
    "            f.write(f'{datetime.now()}: {message}\\n')\n",
    "    except PermissionError:\n",
    "        print(\"Error: Insufficient permissions to write to the log file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(url, table_attribs):\n",
    "    \"\"\"Extracts data from a webpage and returns it as a DataFrame.\n",
    "\n",
    "    This function fetches the webpage content, parses the HTML to locate the\n",
    "    specified table, and converts it into a DataFrame. It logs the progress\n",
    "    and handles exceptions gracefully.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the webpage to extract data from.\n",
    "        table_attribs (str): The attribute of the target table to locate it.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The extracted data as a DataFrame.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If data extraction fails or table is not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch the webpage content\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an HTTPError for bad responses (4xx and 5xx)\n",
    "        \n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('span', string=table_attribs)\n",
    "        \n",
    "        if table is None:\n",
    "            raise ValueError(f\"Table with attributes '{table_attribs}' not found on the webpage.\")\n",
    "\n",
    "        # Extract the table and convert to DataFrame\n",
    "        table = table.find_next('table')\n",
    "        if table is None:\n",
    "            raise ValueError(\"No table found after the specified span.\")\n",
    "\n",
    "        df = pd.read_html(StringIO(str(table)))[0]\n",
    "\n",
    "        # Log progress\n",
    "        log_progress('Data extraction complete. Initiating Transformation process')\n",
    "\n",
    "        return df\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        log_progress(f\"Network error: {e}\")\n",
    "        raise RuntimeError(f\"Failed to fetch URL: {url}. Check your connection or the URL.\") from e\n",
    "\n",
    "    except ValueError as e:\n",
    "        log_progress(f\"Data extraction error: {e}\")\n",
    "        raise\n",
    "\n",
    "    except Exception as e:\n",
    "        log_progress(f\"Unexpected error during extraction: {e}\")\n",
    "        raise RuntimeError(\"An unexpected error occurred during data extraction.\") from e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df, csv_path):\n",
    "    \"\"\"Transforms the DataFrame by adding market capitalization columns in different currencies.\n",
    "\n",
    "    This function reads exchange rate information from a CSV file and adds columns\n",
    "    to the DataFrame for market capitalization in GBP, EUR, INR, and PKR.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing 'Market cap (US$ billion)' column.\n",
    "        csv_path (str): Path to the CSV file with exchange rates.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The transformed DataFrame with additional columns.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If required columns are missing or invalid.\n",
    "        FileNotFoundError: If the exchange rate CSV file is not found.\n",
    "        KeyError: If the necessary exchange rates are not available in the CSV.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate input DataFrame\n",
    "        if 'Market cap (US$ billion)' not in df.columns:\n",
    "            raise ValueError(\"The input DataFrame is missing the 'Market cap (US$ billion)' column.\")\n",
    "\n",
    "        # Load exchange rate data\n",
    "        try:\n",
    "            exchange_rate = pd.read_csv(csv_path, index_col=0).to_dict()['Rate']\n",
    "        except FileNotFoundError:\n",
    "            log_progress(f\"Exchange rate file not found: {csv_path}\")\n",
    "            raise FileNotFoundError(f\"Exchange rate file '{csv_path}' not found.\")\n",
    "        except KeyError:\n",
    "            log_progress(\"The exchange rate file is missing the required 'Rate' column.\")\n",
    "            raise KeyError(\"The exchange rate file is missing the required 'Rate' column.\")\n",
    "\n",
    "        # Add transformed columns\n",
    "        currencies = ['GBP', 'EUR', 'INR', 'PKR']\n",
    "        for currency in currencies:\n",
    "            if currency not in exchange_rate:\n",
    "                log_progress(f\"Exchange rate for {currency} not found in the CSV file.\")\n",
    "                raise KeyError(f\"Exchange rate for {currency} is missing in the exchange rate file.\")\n",
    "\n",
    "            df[f'MC_{currency}_Billion'] = round(df['Market cap (US$ billion)'] * exchange_rate[currency], 2)\n",
    "\n",
    "        # Log success\n",
    "        log_progress(\"Data transformation complete. Initiating Loading process.\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        log_progress(f\"Data transformation failed: {e}\")\n",
    "        raise RuntimeError(f\"An error occurred during data transformation: {e}\") from e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_csv(df, output_path):\n",
    "    \"\"\"Saves the given DataFrame as a CSV file at the specified path.\n",
    "\n",
    "    This function saves the final data frame as a CSV file. If the\n",
    "    output directory doesn't exist, it will attempt to create it.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to save.\n",
    "        output_path (str): The full path (including filename) where the CSV should be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the DataFrame is empty or invalid.\n",
    "        IOError: If there are issues writing the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate DataFrame\n",
    "        if df is None or df.empty:\n",
    "            raise ValueError(\"The provided DataFrame is empty or None.\")\n",
    "        \n",
    "        # Ensure the output directory exists\n",
    "        output_dir = os.path.dirname(output_path)\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        # Save the DataFrame to CSV\n",
    "        df.to_csv(output_path, index=False)\n",
    "\n",
    "        # Log progress\n",
    "        log_progress(f\"Data successfully saved to {output_path}\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        log_progress(f\"Data saving error: {e}\")\n",
    "        raise\n",
    "\n",
    "    except IOError as e:\n",
    "        log_progress(f\"File writing error: {e}\")\n",
    "        raise RuntimeError(f\"Failed to save CSV to {output_path}. Check file permissions or disk space.\") from e\n",
    "\n",
    "    except Exception as e:\n",
    "        log_progress(f\"Unexpected error: {e}\")\n",
    "        raise RuntimeError(f\"An unexpected error occurred while saving CSV: {e}\") from e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_db(df, sql_connection, table_name):\n",
    "    \"\"\"Saves the given DataFrame to a database table.\n",
    "\n",
    "    This function saves the final data frame to a database table with the provided\n",
    "    name. If the DataFrame is empty or there are database issues, it handles\n",
    "    exceptions gracefully.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to save.\n",
    "        sql_connection: A SQLAlchemy database connection or engine.\n",
    "        table_name (str): The name of the database table.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the DataFrame is empty or None.\n",
    "        RuntimeError: For any database-related issues.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate the DataFrame\n",
    "        if df is None or df.empty:\n",
    "            raise ValueError(\"The provided DataFrame is empty or None.\")\n",
    "\n",
    "        # Save the DataFrame to the database\n",
    "        df.to_sql(table_name, sql_connection, if_exists='replace', index=False)\n",
    "\n",
    "        # Log progress\n",
    "        log_progress(f\"Data successfully loaded to the database table '{table_name}'. Executing queries.\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        log_progress(f\"Data loading error: {e}\")\n",
    "        raise\n",
    "\n",
    "    except Exception as e:\n",
    "        log_progress(f\"Unexpected error while loading data to the database: {e}\")\n",
    "        raise RuntimeError(f\"An unexpected error occurred while saving data to the table '{table_name}': {e}\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query_statement, sql_connection):\n",
    "    \"\"\"Runs a query on the database and prints the output.\n",
    "\n",
    "    This function executes the given query on the connected database table\n",
    "    and returns the results. If an error occurs, it logs the error and\n",
    "    re-raises the exception.\n",
    "\n",
    "    Args:\n",
    "        query_statement (str): The SQL query to be executed.\n",
    "        sql_connection: The database connection object.\n",
    "\n",
    "    Returns:\n",
    "        list: The query results as a list of tuples.\n",
    "\n",
    "    Raises:\n",
    "        RuntimeError: For any database-related issues.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a cursor object\n",
    "        cursor = sql_connection.cursor()\n",
    "\n",
    "        # Execute the query\n",
    "        cursor.execute(query_statement)\n",
    "\n",
    "        # Fetch the results\n",
    "        result = cursor.fetchall()\n",
    "\n",
    "        # Log progress\n",
    "        log_progress(\"Query executed successfully. Process complete.\")\n",
    "\n",
    "        return result\n",
    "\n",
    "    except sql_connection.Error as e:\n",
    "        log_progress(f\"Database error: {e}\")\n",
    "        raise RuntimeError(f\"An error occurred while executing the query: {e}\") from e\n",
    "\n",
    "    except Exception as e:\n",
    "        log_progress(f\"Unexpected error during query execution: {e}\")\n",
    "        raise RuntimeError(f\"An unexpected error occurred while executing the query: {e}\") from e\n",
    "\n",
    "    finally:\n",
    "        # Ensure the cursor is closed\n",
    "        if 'cursor' in locals() and cursor:\n",
    "            cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Records:\n",
      "(1, 'JPMorgan Chase', 432.92, 346.34, 419.93, 37231.12, 120351.76)\n",
      "(2, 'Bank of America', 231.52, 185.22, 224.57, 19910.72, 64362.56)\n",
      "(3, 'Industrial and Commercial Bank of China', 194.56, 155.65, 188.72, 16732.16, 54087.68)\n",
      "(4, 'Agricultural Bank of China', 160.68, 128.54, 155.86, 13818.48, 44669.04)\n",
      "(5, 'HDFC Bank', 157.91, 126.33, 153.17, 13580.26, 43898.98)\n",
      "(6, 'Wells Fargo', 155.87, 124.7, 151.19, 13404.82, 43331.86)\n",
      "(7, 'HSBC Holdings PLC', 148.9, 119.12, 144.43, 12805.4, 41394.2)\n",
      "(8, 'Morgan Stanley', 140.83, 112.66, 136.61, 12111.38, 39150.74)\n",
      "(9, 'China Construction Bank', 139.82, 111.86, 135.63, 12024.52, 38869.96)\n",
      "(10, 'Bank of China', 136.81, 109.45, 132.71, 11765.66, 38033.18)\n",
      "\n",
      "Average Market Capitalization (in GBP Billion):\n",
      "151.987\n",
      "\n",
      "First 5 Bank Names:\n",
      "JPMorgan Chase\n",
      "Bank of America\n",
      "Industrial and Commercial Bank of China\n",
      "Agricultural Bank of China\n",
      "HDFC Bank\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        # Input and output paths\n",
    "        url = 'https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks'\n",
    "        output_csv_path = './output/Largest_banks_data.csv'\n",
    "        database_name = './output/Banks.db'\n",
    "        table_name = 'Largest_banks'\n",
    "        \n",
    "        # Log the start of the ETL process\n",
    "        log_progress('Preliminaries complete. Initiating ETL process')\n",
    "\n",
    "        # Extraction\n",
    "        try:\n",
    "            df = extract(url, 'By market capitalization')\n",
    "        except Exception as e:\n",
    "            log_progress(f\"Extraction failed: {e}\")\n",
    "            raise RuntimeError(\"ETL process halted during extraction.\") from e\n",
    "\n",
    "        # Transformation\n",
    "        try:\n",
    "            transform(df, './input/exchange_rate.csv')\n",
    "        except Exception as e:\n",
    "            log_progress(f\"Transformation failed: {e}\")\n",
    "            raise RuntimeError(\"ETL process halted during transformation.\") from e\n",
    "\n",
    "        # Load to CSV\n",
    "        try:\n",
    "            load_to_csv(df, output_csv_path)\n",
    "        except Exception as e:\n",
    "            log_progress(f\"Failed to save data to CSV: {e}\")\n",
    "            raise RuntimeError(\"ETL process halted during CSV load.\") from e\n",
    "\n",
    "        # Load to Database\n",
    "        try:\n",
    "            with sqlite3.connect(database_name) as conn:\n",
    "                load_to_db(df, conn, table_name)\n",
    "\n",
    "                # Query 1: Select all records\n",
    "                try:\n",
    "                    result = run_query('SELECT * FROM Largest_banks', conn)\n",
    "                    print(\"All Records:\")\n",
    "                    for row in result:\n",
    "                        print(row)\n",
    "                except Exception as e:\n",
    "                    log_progress(f\"Query 1 failed: {e}\")\n",
    "                    raise\n",
    "\n",
    "                # Query 2: Calculate the average market capitalization\n",
    "                try:\n",
    "                    result = run_query('SELECT AVG(MC_GBP_Billion) FROM Largest_banks', conn)\n",
    "                    print(\"\\nAverage Market Capitalization (in GBP Billion):\")\n",
    "                    print(result[0][0])\n",
    "                except Exception as e:\n",
    "                    log_progress(f\"Query 2 failed: {e}\")\n",
    "                    raise\n",
    "\n",
    "                # Query 3: Fetch the first five bank names\n",
    "                try:\n",
    "                    result = run_query('SELECT \"Bank name\" FROM Largest_banks LIMIT 5', conn)\n",
    "                    print(\"\\nFirst 5 Bank Names:\")\n",
    "                    for row in result:\n",
    "                        print(row[0])\n",
    "                except Exception as e:\n",
    "                    log_progress(f\"Query 3 failed: {e}\")\n",
    "                    raise\n",
    "        except Exception as e:\n",
    "            log_progress(f\"Database load or query execution failed: {e}\")\n",
    "            raise RuntimeError(\"ETL process halted during database operations.\") from e\n",
    "\n",
    "        log_progress('ETL process completed successfully.')\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log any critical failure in the ETL pipeline\n",
    "        log_progress(f\"ETL process failed: {e}\")\n",
    "        print(f\"Critical Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
